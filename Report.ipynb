{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from Skeletons.Lab_AGX_202223_S2_skeleton import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "CLIENT_ID = \"e597b4ea957b486d98c8935027906fc3\"\n",
    "\n",
    "CLIENT_SECRET = \"084aa7d8cb7c41dc87818e2a92d4a941\"\n",
    "\n",
    "client_credentials_manager = SpotifyClientCredentials(client_id=CLIENT_ID, client_secret=CLIENT_SECRET)\n",
    "sp = spotipy.Spotify(client_credentials_manager=client_credentials_manager)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Firts Session Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_B  = nx.read_graphml('/Users/nbiescas/Desktop/Graphs/Graphs_data/Graph_B.graphml')\n",
    "Graph_D  = nx.read_graphml('/Users/nbiescas/Desktop/Graphs/Graphs_data/Graph_D.graphml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Order of the graphs\n",
    "order_b = Graph_B.order()\n",
    "order_d = Graph_D.order()\n",
    "\n",
    "#Size of the graphs\n",
    "size_b = Graph_B.size()\n",
    "size_d = Graph_D.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#plt.plot(order_DFS, label = \"DFS\")\n",
    "#plt.plot(order_BFS, label = \"BFS\")\n",
    "#plt.xlabel('Position')\n",
    "#plt.ylabel('Value')\n",
    "#plt.title('Line Plot of Incrementing Values')\n",
    "#plt.legend()\n",
    "#plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Degree, Out-Degree and Median in degree of the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph B\n",
    "In_Degree = Graph_B.in_degree(Graph_B.nodes())\n",
    "in_degree_values_sorted = sorted([degree for _, degree in In_Degree])\n",
    "Minimum_In_Degree = in_degree_values_sorted[0]\n",
    "Maximum_In_Degree = in_degree_values_sorted[-1]\n",
    "\n",
    "n = len(in_degree_values_sorted)\n",
    "Median_In_Degree  = in_degree_values_sorted[n // 2] if n % 2 == 1 else (in_degree_values_sorted[n // 2 - 1] + in_degree_values_sorted[n // 2]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame = pd.read_csv('/Users/nbiescas/Desktop/Graphs/Graphs_data/D.csv', index_col=\"song_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_songs  = len(DataFrame.index)\n",
    "number_artist = len(DataFrame.artists.unique())\n",
    "number_albums = len(DataFrame.albums.unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second Session Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Undirected_graph_B  = nx.read_graphml('/Users/nbiescas/Desktop/Graphs/Graphs_data/Undirected_graph_B.graphml')\n",
    "Undirected_graph_D  = nx.read_graphml('/Users/nbiescas/Desktop/Graphs/Graphs_data/Undirected_graph_D.graphml')\n",
    "\n",
    "Undirected_graph_B_weights = nx.read_graphml('/Users/nbiescas/Desktop/Graphs/Graphs_data/Weighted_Graph_B.graphml')\n",
    "Undirected_graph_D_weights = nx.read_graphml('/Users/nbiescas/Desktop/Graphs/Graphs_data/Weighted_Graph_D.graphml')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the order and size of the four obtained undirected graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order Undirected_graph_B: 189\n",
      "\n",
      "Order Undirected_graph_D: 192\n",
      "\n",
      "Order Undirected_graph_B_weights: 177\n",
      "\n",
      "Order Undirected_graph_D_weights: 186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Order Undirected_graph_B: {}\\n\".format(Undirected_graph_B.order()))\n",
    "print(\"Order Undirected_graph_D: {}\\n\".format(Undirected_graph_D.order()))\n",
    "print(\"Order Undirected_graph_B_weights: {}\\n\".format(Undirected_graph_B_weights.order()))\n",
    "print(\"Order Undirected_graph_D_weights: {}\\n\".format(Undirected_graph_D_weights.order()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size Undirected_graph_B: 488\n",
      "\n",
      "Size Undirected_graph_D: 931\n",
      "\n",
      "Size Undirected_graph_B_weights: 435\n",
      "\n",
      "Size Undirected_graph_D_weights: 994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Size Undirected_graph_B: {}\\n\".format(Undirected_graph_B.size()))\n",
    "print(\"Size Undirected_graph_D: {}\\n\".format(Undirected_graph_D.size()))\n",
    "print(\"Size Undirected_graph_B_weights: {}\\n\".format(Undirected_graph_B_weights.size()))\n",
    "print(\"Size Undirected_graph_D_weights: {}\\n\".format(Undirected_graph_D_weights.size()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stronly and Weakly connected Components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weakly connected components\n",
    "weakly_connected_components_Graph_B = list(nx.weakly_connected_components(Graph_B))\n",
    "weakly_connected_components_Graph_D = list(nx.weakly_connected_components(Graph_D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Strongly connected components\n",
    "strongly_connected_components_Graph_B = len(list(nx.strongly_connected_components(Graph_B)))\n",
    "strongly_connected_components_Graph_D = len(list(nx.strongly_connected_components(Graph_D)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected Components in the Undirected graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected components in the undirected graph B: 2\n",
      "Connected components in the undirected graph D: 5\n"
     ]
    }
   ],
   "source": [
    "#Strongly connected components\n",
    "connected_components_undirected_B = nx.number_connected_components(Undirected_graph_B)\n",
    "connected_components_undirected_D = nx.number_connected_components(Undirected_graph_D)\n",
    "print(\"Connected components in the undirected graph B: {}\\nConnected components in the undirected graph D: {}\".format(connected_components_undirected_B, connected_components_undirected_D))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Size of the largest connected component of the Undirected graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size largest connected component:\n",
      "\n",
      "Undirected graph B: Graph with 187 nodes and 487 edges\n",
      "Undirected graph D: Graph with 90 nodes and 481 edges\n"
     ]
    }
   ],
   "source": [
    "largets_connected_component_B = max(list(nx.connected_components(Undirected_graph_B)), key=len)\n",
    "largets_connected_component_D = max(list(nx.connected_components(Undirected_graph_D)), key=len)\n",
    "\n",
    "\n",
    "largets_connected_component_B_sub = Undirected_graph_B.subgraph(largets_connected_component_B)\n",
    "largets_connected_component_D_sub = Undirected_graph_D.subgraph(largets_connected_component_D)\n",
    "\n",
    "print(\"Size largest connected component:\\n\\nUndirected graph B: {}\\nUndirected graph D: {}\".format(largets_connected_component_B_sub, largets_connected_component_D_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density for the graph largets connected component B 0.028002990052325916\n",
      "Density for the graph largets connected component D 0.12009987515605493\n"
     ]
    }
   ],
   "source": [
    "print(\"Density for the graph largets connected component B {}\".format(nx.density(largets_connected_component_B_sub)))\n",
    "print(\"Density for the graph largets connected component D {}\".format(nx.density(largets_connected_component_D_sub)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Radius for the largets connected component B 10\n",
      "Radius for the largets connected component D 5\n"
     ]
    }
   ],
   "source": [
    "print(\"Radius for the largets connected component B {}\".format(nx.radius(largets_connected_component_B_sub)))\n",
    "print(\"Radius for the largets connected component D {}\".format(nx.radius(largets_connected_component_D_sub)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.community.centrality import girvan_newman\n",
    "from networkx.algorithms.community import louvain_communities, modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_B  = nx.read_graphml(r'C:\\Users\\xavim\\Desktop\\Uni\\2n\\2\\Graphs\\Project\\Graphs\\Graph_B.graphml')\n",
    "Graph_fb = nx.read_graphml(r'C:\\Users\\xavim\\Desktop\\Uni\\2n\\2\\Graphs\\Project\\Graphs\\Graph_fb.graphml')\n",
    "Graph_Hb = nx.read_graphml(r'C:\\Users\\xavim\\Desktop\\Uni\\2n\\2\\Graphs\\Project\\Graphs\\Graph_HB.graphml')\n",
    "Graph_D = nx.read_graphml(r'C:\\Users\\xavim\\Desktop\\Uni\\2n\\2\\Graphs\\Project\\Graphs\\Graph_D.graphml')\n",
    "Graph_B_und = nx.read_graphml(r'C:\\Users\\xavim\\Desktop\\Uni\\2n\\2\\Graphs\\Project\\Graphs\\Undirected_graph_B.graphml')\n",
    "Graph_D_und = nx.read_graphml(r'C:\\Users\\xavim\\Desktop\\Uni\\2n\\2\\Graphs\\Project\\Graphs\\Undirected_graph_D.graphml')\n",
    "Graph_B_w = nx.read_graphml(r'C:\\Users\\xavim\\Desktop\\Uni\\2n\\2\\Graphs\\Project\\Graphs\\Weighted_Graph_B.graphml')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Common nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_common_nodes(*arg):\n",
    "    \"\"\"\n",
    "    Return the number of common nodes between a set of graphs.\n",
    "\n",
    "    :param arg: (an undetermined number of) networkx graphs.\n",
    "    :return: an integer, number of common nodes.\n",
    "    \"\"\"\n",
    "    # ------- IMPLEMENT HERE THE BODY OF THE FUNCTION ------- #\n",
    "    common_nodes = set(arg[0].nodes)\n",
    "    for graph in arg[1:]:\n",
    "        nodes = set(graph.nodes)\n",
    "        common_nodes = common_nodes.intersection(nodes)\n",
    "\n",
    "    return len(common_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of common nodes between B and fB: {}\".format(num_common_nodes(Graph_B, Graph_fb)))\n",
    "print(\"Number of common nodes between B and hB: {}\".format(num_common_nodes(Graph_B, Graph_Hb)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most central nodes and intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_most_central(g: nx.Graph, metric: str, num_nodes: int) -> list:\n",
    "    \"\"\"\n",
    "    Get the k most central nodes in the graph.\n",
    "\n",
    "    :param g: networkx graph.\n",
    "    :param metric: centrality metric. Can be (at least) 'degree', 'betweenness', 'closeness' or 'eigenvector'.\n",
    "    :param num_nodes: number of nodes to return.\n",
    "    :return: list with the top num_nodes nodes with the specified centrality.\n",
    "    \"\"\"\n",
    "    # ------- IMPLEMENT HERE THE BODY OF THE FUNCTION ------- #\n",
    "    if metric == \"degree\":\n",
    "        most_central = sorted(nx.degree_centrality(g).items(), key=lambda item: item[1], reverse=True)[:num_nodes]\n",
    "    elif metric == \"betweenness\":\n",
    "        most_central = sorted(nx.betweenness_centrality(g).items(), key=lambda item: item[1], reverse=True)[:num_nodes]\n",
    "    elif metric == \"closeness\":\n",
    "        most_central = sorted(nx.closeness_centrality(g).items(), key=lambda item: item[1], reverse=True)[:num_nodes]\n",
    "    elif metric == \"eigenvector\":\n",
    "        most_central = sorted(nx.eigenvector_centrality(g).items(), key=lambda item: item[1], reverse=True)[:num_nodes]\n",
    "    elif metric == \"page rank\":\n",
    "        most_central = sorted(nx.pagerank(g).items(), key=lambda item: item[1], reverse=True)[:num_nodes]\n",
    "    \n",
    "    return most_central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg = get_k_most_central(Graph_B, metric = \"degree\", num_nodes= 25)\n",
    "betw = get_k_most_central(Graph_B, metric= \"betweenness\", num_nodes= 25)\n",
    "\n",
    "print(deg)\n",
    "print(betw)\n",
    "\n",
    "deg_nodes = {item[0] for item in deg}\n",
    "betw_nodes = {item[0] for item in betw}\n",
    "\n",
    "common_nodes = deg_nodes.intersection(betw_nodes)\n",
    "\n",
    "print(\"The common nodes are {}\".format(common_nodes))    \n",
    "print(\"The amount of common nodes is {}\".format(len(common_nodes)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cliques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cliques(g: nx.Graph, min_size_clique: int) -> tuple:\n",
    "    \"\"\"\n",
    "    Find cliques in the graph g with size at least min_size_clique.\n",
    "\n",
    "    :param g: networkx graph.\n",
    "    :param min_size_clique: minimum size of the cliques to find.\n",
    "    :return: two-element tuple, list of cliques (each clique is a list of nodes) and\n",
    "        list of nodes in any of the cliques.\n",
    "    \"\"\"\n",
    "    # ------- IMPLEMENT HERE THE BODY OF THE FUNCTION ------- #\n",
    "    cliques = [clic for clic in nx.find_cliques(g) if len(clic) >= min_size_clique]\n",
    "    clique_nodes = list(set(node for clique in cliques for node in clique))\n",
    "\n",
    "    return cliques, clique_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB = find_cliques(Graph_B_und, min_size_clique = 7)\n",
    "GD = find_cliques(Graph_D_und, min_size_clique = 10)\n",
    "print(\"There are {} cliques of length 7 in graph B\".format(len(GB[0])))\n",
    "print(\"There are {} cliques of lenght 10 in graph D\".format(len(GD[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_art = GB[1]\n",
    "art = {}\n",
    "for artists in GB_art:\n",
    "    artist = sp.artist(artists)\n",
    "    name = artist['name']\n",
    "    followers = artist['followers']['total']\n",
    "    popularity = artist['popularity']\n",
    "    genres = artist['genres']\n",
    "    art[name] = {\"followers\": followers, \"popularity\": popularity, \"genres\": genres}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "art = pd.DataFrame(art).T\n",
    "\n",
    "max_followers = art['followers'].max()\n",
    "min_followers = art['followers'].min()\n",
    "range_followers = max_followers - min_followers\n",
    "\n",
    "# Find the minimum popularity\n",
    "min_popularity = art['popularity'].min()\n",
    "max_popularity = art['popularity'].max()\n",
    "range_popularity = max_popularity - min_popularity\n",
    "\n",
    "\n",
    "\n",
    "# Find the intersection of genres\n",
    "all_genres = set()\n",
    "\n",
    "for genres_list in art['genres']:\n",
    "    for genre in genres_list:\n",
    "        all_genres.add(genre)\n",
    "\n",
    "count = sum(1 for genre in all_genres if 'hip hop' in genre or 'rap' in genre)\n",
    "\n",
    "print(\"Min followers: {}\".format(min_followers))\n",
    "print(\"Max followers: {}\".format(max_followers))\n",
    "print(\"Range of followers: {}\".format(range_followers))\n",
    "\n",
    "print(\"Min popularity: {}\".format(min_popularity))\n",
    "print(\"Max popularity: {}\".format(max_popularity))\n",
    "print(\"Range popularity: {}\".format(range_popularity))\n",
    "\n",
    "print(\"Amount of different genres: {}\".format(len(all_genres)))\n",
    "\n",
    "print(\"Amount of genres that are hip hop or rap: {}\".format(count))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Community detection (louvain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_communities(g: nx.Graph, method: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Detect communities in the graph g using the specified method.\n",
    "\n",
    "    :param g: a networkx graph.\n",
    "    :param method: string with the name of the method to use. Can be (at least) 'givarn-newman' or 'louvain'.\n",
    "    :return: two-element tuple, list of communities (each community is a list of nodes) and modularity of the partition.\n",
    "    \"\"\"\n",
    "    # ------- IMPLEMENT HERE THE BODY OF THE FUNCTION ------- #\n",
    "    if method == \"girvan_newman\":\n",
    "        communities = girvan_newman(g)\n",
    "    \n",
    "    elif method == \"louvain\":\n",
    "        communities = louvain_communities(g)\n",
    "\n",
    "    modularity_partition = modularity(g, communities)\n",
    "\n",
    "    return communities, modularity_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comunity, modularity = detect_communities(Graph_D, \"louvain\")\n",
    "print(\"The modularity is: {}\".format(modularity))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nodes to put the ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "betw_B = get_k_most_central(Graph_B, metric= \"betweenness\", num_nodes= 4)\n",
    "print(\"The most important nodes of graph B are: {}\".format(betw))\n",
    "betw_D = get_k_most_central(Graph_D, metric= \"betweenness\", num_nodes= 4)\n",
    "print(\"The most important nodes of graph D are: {}\".format(betw))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shortest path(Young Dro - Travis Porter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = nx.shortest_path(Graph_B, \"3ZooCJzNMTLpmJaIRUEorI\", \"6z1cicLMt9XArxN10q7m8a\")\n",
    "print(\"There are {} hops between the 2 artists\".format(len(nodes)-1))\n",
    "print(\"The nodes are: {}\".format(nodes))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_B_und = nx.read_graphml(r'C:\\Users\\xavim\\Desktop\\Uni\\2n\\2\\Graphs\\Project\\Graphs\\Undirected_graph_B.graphml')\n",
    "Graph_D_und = nx.read_graphml(r'C:\\Users\\xavim\\Desktop\\Uni\\2n\\2\\Graphs\\Project\\Graphs\\Undirected_graph_D.graphml')\n",
    "Graph_B_w = nx.read_graphml(r'C:\\Users\\xavim\\Desktop\\Uni\\2n\\2\\Graphs\\Project\\Graphs\\Weighted_Graph_B.graphml')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plots degree distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_degree_distribution(g: nx.Graph) -> dict:\n",
    "    \"\"\"\n",
    "    Get the degree distribution of the graph.\n",
    "\n",
    "    :param g: networkx graph.\n",
    "    :return: dictionary with degree distribution (keys are degrees, values are number of occurrences).\n",
    "    \"\"\"\n",
    "    # ------- IMPLEMENT HERE THE BODY OF THE FUNCTION ------- #\n",
    "    degree_count = nx.degree_histogram(g)\n",
    "    degree_distribution = {degree: count for degree, count in enumerate(degree_count)}\n",
    "    return degree_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deg_dist_B = get_degree_distribution(Graph_B_und)\n",
    "deg_dist_D = get_degree_distribution(Graph_D_und)\n",
    "deg_dist_B_w = get_degree_distribution(Graph_B_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_degree_distribution(degree_dict: dict, normalized: bool = False, loglog: bool = False) -> None:\n",
    "    \"\"\"\n",
    "    Plot degree distribution from dictionary of degree counts.\n",
    "\n",
    "    :param degree_dict: dictionary of degree counts (keys are degrees, values are occurrences).\n",
    "    :param normalized: boolean indicating whether to plot absolute counts or probabilities.\n",
    "    :param loglog: boolean indicating whether to plot in log-log scale.\n",
    "    \"\"\"\n",
    "    # ------- IMPLEMENT HERE THE BODY OF THE FUNCTION ------- #\n",
    "    degrees = list(degree_dict.keys())\n",
    "    counts = list(degree_dict.values())\n",
    "\n",
    "    if normalized:\n",
    "        total_nodes = sum(counts)\n",
    "        counts = [count / total_nodes for count in counts]\n",
    "\n",
    "    if loglog:\n",
    "        plt.loglog(degrees, counts, 'bo-')\n",
    "        plt.xlabel('Degree', fontsize=12)\n",
    "        plt.ylabel('Probability' if normalized else 'Count', fontsize=12)\n",
    "        plt.title('Degree Distribution (Log-Log Scale)', fontsize=14)\n",
    "    else:\n",
    "        plt.plot(degrees, counts, 'bo-')\n",
    "        plt.xlabel('Degree', fontsize=12)\n",
    "        plt.ylabel('Probability' if normalized else 'Count', fontsize=12)\n",
    "        plt.title('Degree Distribution', fontsize=14)\n",
    "\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undirected graph B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_degree_distribution(deg_dist_B,normalized = True, loglog= False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undirected graph D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_degree_distribution(deg_dist_D,normalized = False, loglog = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph B with weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_degree_distribution(deg_dist_B_w,normalized = False, loglog= False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparison of audio features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most and less similiar artist from Drake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_B_pandas           = pd.read_csv('/Users/nbiescas/Desktop/Graphs/Graphs_data/Pandas_Graph_B.csv', index_col='song_id')\n",
    "Mean_audio_features_data = compute_mean_audio_features(Graph_B_pandas)\n",
    "result                   = create_similarity_graph(Mean_audio_features_data, similarity = 'cosine', out_filename=\"l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Drake_id = Mean_audio_features_data[Mean_audio_features_data['artist_name'] == 'Drake']['artist_id'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtantion of the edges of drake. Using the max and min function obtention of the edge with higher weight or lower weight. Once we have found the edge of interest retrive the id at postion [1]\n",
    "More_similiar = max(list(result.edges(Drake_id, data=True)), key = lambda x : x[2]['weight'])[1]\n",
    "Less_similiar = min(list(result.edges(Drake_id, data=True)), key = lambda x : x[2]['weight'])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guerilla Maab'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mean_audio_features_data.loc[More_similiar]['artist_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lil Sancho'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mean_audio_features_data.loc[Less_similiar]['artist_name']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Graph_D_pandas           = pd.read_csv('/Users/nbiescas/Desktop/Graphs/Graphs_data/Pandas_Graph_D.csv', index_col='song_id')\n",
    "Mean_audio_features_data = compute_mean_audio_features(Graph_D_pandas)\n",
    "result                   = create_similarity_graph(Mean_audio_features_data, similarity = 'cosine', out_filename=\"l\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obtantion of the edges of drake. Using the max and min function obtention of the edge with higher weight or lower weight. Once we have found the edge of interest retrive the id at postion [1]\n",
    "More_similiar = max(list(result.edges(Drake_id, data=True)), key = lambda x : x[2]['weight'])[1]\n",
    "Less_similiar = min(list(result.edges(Drake_id, data=True)), key = lambda x : x[2]['weight'])[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guerilla Maab'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mean_audio_features_data.loc[More_similiar]['artist_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lil Sancho'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Mean_audio_features_data.loc[Less_similiar]['artist_name']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_columns(artist_audio_feat_B):\n",
    "    columns_to_normalize = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness',\n",
    "                        'liveness', 'valence', 'tempo']\n",
    "\n",
    "    for column in columns_to_normalize:\n",
    "        min_value = artist_audio_feat_B[column].min()\n",
    "        max_value = artist_audio_feat_B[column].max()\n",
    "        artist_audio_feat_B[column] = (artist_audio_feat_B[column] - min_value) / (max_value - min_value)\n",
    "    \n",
    "    return artist_audio_feat_B"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_audio_features_bar(artists_audio_feat: pd.DataFrame, artist1_id: str, artist2_id: str) -> None:\n",
    "    \"\"\"\n",
    "    Plot a single figure with a plot of mean audio features of two different artists.\n",
    "\n",
    "    :param artists_audio_feat: dataframe with mean audio features of artists.\n",
    "    :param artist1_id: string with id of artist 1.\n",
    "    :param artist2_id: string with id of artist 2.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # Filter the dataframe for the two artists\n",
    "    artist1_data = artists_audio_feat[artists_audio_feat['artist_name'] == artist1_id]\n",
    "    artist2_data = artists_audio_feat[artists_audio_feat['artist_name'] == artist2_id]\n",
    "\n",
    "    # Get the audio feature labels and their positions on the x-axis\n",
    "    audio_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness',\n",
    "                      'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "    x_pos = np.arange(len(audio_features))\n",
    "\n",
    "    # Get the mean values of audio features for artist 1 and artist 2\n",
    "    artist1_values = artist1_data[audio_features].values[0]\n",
    "    artist2_values = artist2_data[audio_features].values[0]\n",
    "\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    # Plot the bar chart for artist 1\n",
    "    ax.bar(x_pos, artist1_values, width=0.4, align='center', label=artist1_id)\n",
    "\n",
    "    # Plot the bar chart for artist 2\n",
    "    ax.bar(x_pos + 0.4, artist2_values, width=0.4, align='center', label=artist2_id)\n",
    "\n",
    "    # Set the x-axis ticks and labels\n",
    "    ax.set_xticks(x_pos + 0.2)\n",
    "    ax.set_xticklabels(audio_features, rotation=45, ha='right')\n",
    "\n",
    "    # Set the axis labels and title\n",
    "    ax.set_xlabel('Audio Features')\n",
    "    ax.set_ylabel('Mean Value')\n",
    "    ax.set_title('Comparison of Mean Audio Features')\n",
    "\n",
    "    # Add a legend\n",
    "    ax.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radar plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_audio_features_radar(artists_audio_feat: pd.DataFrame, artist1_id: str, artist2_id: str) -> None:\n",
    "    \"\"\"\n",
    "    Plot a single figure with a radar plot of mean audio features of two different artists.\n",
    "\n",
    "    :param artists_audio_feat: dataframe with mean audio features of artists.\n",
    "    :param artist1_id: string with id of artist 1.\n",
    "    :param artist2_id: string with id of artist 2.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # Filter the dataframe for the two artists\n",
    "    artist1_data = artists_audio_feat[artists_audio_feat['artist_name'] == artist1_id]\n",
    "    artist2_data = artists_audio_feat[artists_audio_feat['artist_name'] == artist2_id]\n",
    "\n",
    "    # Get the audio feature labels and their positions on the radar plot\n",
    "    audio_features = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness',\n",
    "                      'instrumentalness', 'liveness', 'valence', 'tempo']\n",
    "    \n",
    "    angles = np.linspace(0, 2 * np.pi, len(audio_features), endpoint=False).tolist()\n",
    "    angles += angles[:1]  # Repeat the first angle to close the plot\n",
    "\n",
    "    # Get the mean values of audio features for artist 1 and artist 2\n",
    "    artist1_values = artist1_data[audio_features].values[0].tolist()\n",
    "    artist1_values += artist1_values[:1]  # Repeat the first value to close the plot\n",
    "\n",
    "    artist2_values = artist2_data[audio_features].values[0].tolist()\n",
    "    artist2_values += artist2_values[:1]  # Repeat the first value to close the plot\n",
    "\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(8, 8), subplot_kw={'projection': 'polar'})\n",
    "\n",
    "    # Plot the radar plot for artist 1\n",
    "    ax.plot(angles, artist1_values, label=artist1_id)\n",
    "    ax.fill(angles, artist1_values, alpha=0.25)\n",
    "\n",
    "    # Plot the radar plot for artist 2\n",
    "    ax.plot(angles, artist2_values, label=artist2_id)\n",
    "    ax.fill(angles, artist2_values, alpha=0.25)\n",
    "\n",
    "    # Set the angle ticks and labels\n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(audio_features, fontsize=8)\n",
    "\n",
    "    # Set the y-axis labels and limits\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_yticks([0.2, 0.4, 0.6, 0.8])\n",
    "    ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8'])\n",
    "\n",
    "    # Set the title and legend\n",
    "    ax.set_title('Comparison of Mean Audio Features', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_audio_feat_B = pd.read_csv(r'C:\\Users\\xavim\\Desktop\\Uni\\2n\\2\\Graphs\\Project\\Graphs\\Mean_Audio_Features_graph_B.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_audio_feat_B_norm = normalize_columns(artist_audio_feat_B)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_audio_features_bar(artist_audio_feat_B_norm, \"Drake\", \"Lil Keed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_audio_features_radar(artist_audio_feat_B_norm, \"Drake\", \"Lil Keed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_audio_features_bar(artist_audio_feat_B_norm, 'Drake', 'Lil Scrappy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_audio_features_radar(artist_audio_feat_B_norm, 'Drake', 'Lil Scrappy')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_audio_feat_D = pd.read_csv(r'C:\\Users\\xavim\\Desktop\\Uni\\2n\\2\\Graphs\\Project\\Graphs\\Mean_Audio_Features_graph_D.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_audio_feat_D_norm = normalize_columns(artist_audio_feat_D)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_audio_features_bar(artist_audio_feat_D_norm, \"Drake\", \"Guerilla Maab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_audio_features_radar(artist_audio_feat_D_norm, \"Drake\", \"Guerilla Maab\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Less similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_audio_features_bar(artist_audio_feat_D_norm, \"Drake\", \"Lil Sancho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_audio_features_radar(artist_audio_feat_D_norm, \"Drake\", \"Lil Sancho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similarity_heatmap(artist_audio_features: pd.DataFrame, similarity: str, out_filename: str = None) -> None:\n",
    "    \"\"\"\n",
    "    Plot a heatmap of the similarity between artists.\n",
    "\n",
    "    :param artist_audio_features_df: dataframe with mean audio features of artists.\n",
    "    :param similarity: string with similarity measure to use.\n",
    "    :param out_filename: name of the file to save the plot. If None, the plot is not saved.\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    # Compute the similarity matrix\n",
    "    similarity_matrix = artist_audio_features.drop('artist_id', axis=1).corr(method=similarity)\n",
    "\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    # Generate the heatmap\n",
    "    sns.heatmap(similarity_matrix, cmap='coolwarm', annot=True, fmt=\".2f\", cbar=True, square=True, ax=ax)\n",
    "\n",
    "    # Set the title and labels\n",
    "    ax.set_title(f\"Similarity Heatmap ({similarity})\")\n",
    "    ax.set_xlabel(\"Artists\")\n",
    "    ax.set_ylabel(\"Artists\")\n",
    "\n",
    "    # Save the plot if a filename is provided\n",
    "    if out_filename is not None:\n",
    "        plt.savefig(out_filename)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_similarity_heatmap(artist_audio_feat_B, \"pearson\", 'similarity_heatmap.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
